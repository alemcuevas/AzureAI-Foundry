# Módulo 4: Seguridad, Gobernanza y Responsible AI en AI Foundry

## Introducción

AI Foundry está diseñado bajo los principios de Responsible AI de Microsoft, con capacidades nativas de seguridad, monitoreo, cumplimiento y gobernanza empresarial.

Este módulo describe los controles de seguridad y gobernanza que AI Foundry implementa de forma nativa dentro del ecosistema Azure.

---

## Principios de Responsible AI en Microsoft

- **Fairness:** Evitar sesgos injustos o discriminatorios.
- **Reliability & Safety:** Garantizar el correcto funcionamiento de los modelos.
- **Privacy & Security:** Protección de datos sensibles.
- **Inclusiveness:** Acceso y uso inclusivo de la IA.
- **Transparency:** Explicabilidad y trazabilidad.
- **Accountability:** Responsabilidad corporativa sobre el uso de IA.

AI Foundry implementa estos principios de forma práctica en sus evaluadores, arquitecturas y validadores.

---

## Evaluadores de Seguridad (Safety Evaluators)

### 1. Groundedness Evaluator

- Verifica la consistencia factual de las respuestas.
- Reduce riesgos de alucinación (hallucination).
- Compara los outputs generados contra fuentes grounding definidas (bases de datos, documentos, APIs).

### 2. Content Safety Evaluators

- Detectan contenidos ofensivos, inapropiados o inseguros.
- Filtran toxicidad, lenguaje ofensivo, odio, violencia, autolesiones, contenido sexual explícito.
- Adaptables a políticas corporativas.

### 3. Factual Consistency Evaluator

- Evalúa si las respuestas generadas respetan la información grounding configurada.
- Permite validar que los agentes se mantengan fieles a los datos empresariales.

### 4. Hallucination Risk Evaluator

- Identifica riesgos de generación de contenido no verificado o fabricado.
- Proporciona puntuaciones de riesgo de alucinación.

### 5. Custom Safety Evaluators

- Permite definir validadores adicionales mediante reglas corporativas personalizadas.
- Ejemplos: detección de datos PII, políticas sectoriales, lenguaje prohibido.

---

## Gobernanza de Datos

### 1. Integración con Azure Purview

- Clasificación automática de datos.
- Identificación de información sensible (PII, PHI, PCI).
- Data Lineage y trazabilidad de uso de datos.
- Creación de políticas de acceso y gobernanza.

### 2. Control de acceso con Managed Identity

- Control granular de acceso a los recursos utilizados por los agents.
- Protección de secrets y claves usando Azure Key Vault.
- Autenticación federada a sistemas externos.

### 3. Control de almacenamiento de memorias

- Memories almacenadas bajo cuentas de almacenamiento de Azure (Storage, SQL, Cosmos DB).
- Soporte a encriptación en reposo (Azure Encryption-at-Rest).
- Control de retención de datos históricos.

### 4. Aislamiento de recursos empresariales

- Capacidad de segregar ambientes de AI Foundry por:
  - Línea de negocio.
  - País o región.
  - Subsidiaria.
  - Sensibilidad de datos.

---

## Auditoría y Monitoreo

### 1. Integración nativa con Azure Monitor

- Logs de invocación de agentes.
- Trazabilidad completa de llamadas a Foundation Models.
- Visualización de resultados de evaluadores de safety.
- Análisis de costos y consumo de tokens.

### 2. Retención de logs empresariales

- Exportación de logs a Azure Log Analytics o SIEM corporativos.
- Integración con Microsoft Sentinel.

### 3. Alertas de seguridad

- Configuración de alertas ante eventos críticos:
  - Fallos en evaluadores.
  - Generación de respuestas bloqueadas.
  - Excesos de costos.
  - Incidentes de compliance.

---

## Protección de Datos Sensibles

### 1. Identificación de PII

- Detección automática de:
  - Nombres.
  - Identificaciones personales.
  - Direcciones.
  - Cuentas bancarias.
  - Información de salud (PHI).

### 2. Redacción automática (Redaction)

- Remoción o anonimización automática de datos sensibles en las respuestas generadas.

### 3. Controles de retención de datos

- Definición de políticas de retención conforme a normas regulatorias (GDPR, HIPAA, PCI).

---

## Controles Operativos

| Área | Capacidad |
|------|------------|
| Control de costos | Configuración de límites de uso por agente, proyecto o suscripción. |
| Control de recursos | Restricción de acceso a modelos, tools y memories por rol. |
| Control de regiones | Despliegue geográfico controlado conforme a normas regulatorias. |
| Control de escalabilidad | Ajuste dinámico de consumo según carga y demanda. |

---

## Integración con el ecosistema de seguridad de Azure

- Azure Active Directory (Entra ID).
- Azure Key Vault.
- Azure Purview.
- Azure Monitor.
- Azure Policy.
- Azure Resource Locks.
- Azure Cost Management.
- Microsoft Sentinel.

---

## Links útiles

- [Responsible AI en Microsoft](https://www.microsoft.com/en-us/ai/responsible-ai)
- [AI Foundry Safety Evaluators](https://learn.microsoft.com/en-us/azure/ai-studio/foundry/safety-evaluators)
- [Gobernanza de datos en Azure Purview](https://learn.microsoft.com/en-us/azure/purview/overview)
- [Azure Monitor - Logs de AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/foundry/monitor-agents)
- [Azure Key Vault para AI Foundry](https://learn.microsoft.com/en-us/azure/key-vault/general/overview)
